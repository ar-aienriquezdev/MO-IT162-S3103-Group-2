{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# FinMarks \u2014 Exploratory Data Analysis & Data Visualization (EDA)\n\n**Generated:** 2025-10-11 16:58\n\nThis notebook loads **`merged_cleaned_dataset.csv`** and produces:\n- Histograms, line chart, bar charts\n- Correlation heatmap (numeric)\n- Association matrix (categoricals, Cram\u00e9r\u2019s V)\n- Inferential tests (Pearson/Spearman, t-test, ANOVA, Chi-square)\n- Age binning + IQR outlier flagging/removal + *pre vs post* plots\n\nOutputs are saved to `eda_outputs/`."}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# --- Setup & Load\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt, seaborn as sns\nfrom pathlib import Path\nfrom scipy import stats\nimport scipy.stats as ss\nfrom statsmodels.tsa.stattools import adfuller\n\nplt.rcParams[\"figure.dpi\"] = 110\nsns.set(style=\"whitegrid\", palette=\"muted\", font_scale=1.05)\n\nDATA_PATH = Path(\"merged_cleaned_dataset.csv\")\nOUT_DIR = Path(\"eda_outputs\"); OUT_DIR.mkdir(exist_ok=True)\n\ndf = pd.read_csv(DATA_PATH)\ndf.columns = df.columns.str.lower()\n\nif \"signupdate\" in df.columns:\n    df[\"signupdate\"] = pd.to_datetime(df[\"signupdate\"], errors=\"coerce\")\n\nfor c in [\"age\",\"total_spent\",\"avg_spent\",\"num_transactions\",\"max_transaction\",\"min_transaction\",\"engagement_score\"]:\n    if c in df.columns:\n        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\nprint(\"Loaded:\", df.shape)\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Part A \u2014 Core Visuals & Base Tests (Code 1)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "def save_show(fig, name):\n    p = OUT_DIR / f\"{name}.png\"\n    fig.savefig(p, bbox_inches=\"tight\"); plt.show()\n    print(f\"Saved: {p}\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Histograms\nif \"age\" in df.columns:\n    fig = plt.figure(figsize=(6,4)); sns.histplot(df[\"age\"].dropna(), bins=25, kde=True)\n    plt.title(\"Age Distribution\"); plt.xlabel(\"Age\"); plt.ylabel(\"Count\")\n    save_show(fig, \"hist_age\")\n\nif \"total_spent\" in df.columns:\n    fig = plt.figure(figsize=(6,4)); sns.histplot(df[\"total_spent\"].dropna(), bins=30, kde=True)\n    plt.title(\"Distribution of Total Spending per Customer\"); plt.xlabel(\"Total Spent\"); plt.ylabel(\"Customers\")\n    save_show(fig, \"hist_total_spent\")\n\nif \"num_transactions\" in df.columns:\n    fig = plt.figure(figsize=(6,4)); sns.histplot(df[\"num_transactions\"].dropna(), bins=30, kde=False)\n    plt.title(\"Number of Transactions per Customer\"); plt.xlabel(\"Transactions\"); plt.ylabel(\"Customers\")\n    save_show(fig, \"hist_num_transactions\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Line chart (monthly)\nif \"signupdate\" in df.columns and \"total_spent\" in df.columns:\n    ts = (df.dropna(subset=[\"signupdate\",\"total_spent\"])\n            .set_index(\"signupdate\")[\"total_spent\"]\n            .resample(\"MS\").sum())\n    fig = plt.figure(figsize=(9,4)); ts.plot()\n    plt.title(\"Total Spending Over Time (monthly)\"); plt.xlabel(\"Month\"); plt.ylabel(\"Sales (sum per month)\")\n    save_show(fig, \"line_total_spent_over_time\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Bar charts\ndef top_bar(col, topn=10, title=None):\n    vc = df[col].astype(\"category\").value_counts().head(topn)\n    fig = plt.figure(figsize=(7,4)); sns.barplot(x=vc.index.astype(str), y=vc.values)\n    plt.title(title or f\"Top {topn} {col.title()}\"); plt.xlabel(col.title()); plt.ylabel(\"Count\")\n    plt.xticks(rotation=30, ha=\"right\"); save_show(fig, f\"bar_{col}_top{topn}\")\n\nfor cat in [\"gender\",\"incomelevel\",\"location\"]:\n    if cat in df.columns:\n        top_bar(cat, topn=10 if cat==\"location\" else df[cat].nunique(), title=f\"Distribution of {cat.title()}\")\n\nif \"gender\" in df.columns and \"total_spent\" in df.columns:\n    fig = plt.figure(figsize=(6,4))\n    sns.barplot(data=df, x=\"gender\", y=\"total_spent\", estimator=sum, errorbar=None)\n    plt.title(\"Total Spending by Gender\"); plt.xlabel(\"Gender\"); plt.ylabel(\"Total Sales (sum)\")\n    save_show(fig, \"bar_total_spent_by_gender\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Box plots\nfor col in [\"total_spent\",\"avg_spent\",\"max_transaction\",\"min_transaction\",\"engagement_score\"]:\n    if col in df.columns:\n        fig = plt.figure(figsize=(6,4)); sns.boxplot(x=df[col].dropna())\n        plt.title(f\"Boxplot of {col}\"); save_show(fig, f\"box_{col}\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Correlation heatmap\nnum_df = df.select_dtypes(include=[\"number\"]).copy()\nif not num_df.empty:\n    corr = num_df.corr(numeric_only=True)\n    fig = plt.figure(figsize=(9,6))\n    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, fmt=\".2f\")\n    plt.title(\"Correlation Heatmap (Numeric Features)\")\n    save_show(fig, \"heatmap_correlation_numeric\")\n    corr.to_csv(OUT_DIR / \"correlation_matrix_numeric.csv\", index=True)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Association matrix (Cram\u00e9r's V)\ndef cramers_v(x, y):\n    tbl = pd.crosstab(x, y); chi2 = ss.chi2_contingency(tbl)[0]; n = tbl.sum().sum()\n    phi2 = chi2 / max(n, 1); r, k = tbl.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1)) if n > 1 else 0\n    rcorr = r - ((r-1)**2)/(n-1) if n > 1 else r\n    kcorr = k - ((k-1)**2)/(n-1) if n > 1 else k\n    denom = min((kcorr-1), (rcorr-1)); \n    return np.sqrt(phi2corr / denom) if denom > 0 else 0.0\n\ncat_df = df.select_dtypes(include=[\"object\",\"category\"]).copy()\nif not cat_df.empty:\n    cat_cols = [c for c in cat_df.columns if cat_df[c].nunique() > 1]\n    assoc = pd.DataFrame(np.zeros((len(cat_cols), len(cat_cols))), index=cat_cols, columns=cat_cols, dtype=float)\n    for i, c1 in enumerate(cat_cols):\n        for j, c2 in enumerate(cat_cols):\n            if i <= j:\n                v = 1.0 if c1 == c2 else cramers_v(cat_df[c1], cat_df[c2])\n                assoc.loc[c1, c2] = assoc.loc[c2, c1] = v\n    fig = plt.figure(figsize=(9,6))\n    sns.heatmap(assoc, annot=True, cmap=\"Purples\", vmin=0, vmax=1, fmt=\".2f\")\n    plt.title(\"Association Matrix (Categorical Features - Cram\u00e9r\u2019s V)\")\n    save_show(fig, \"heatmap_association_categoricals\")\n    assoc.to_csv(OUT_DIR / \"association_matrix_categoricals.csv\", index=True)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Inferential tests (base)\nresults_lines = []\npairs = [(\"age\",\"total_spent\"), (\"num_transactions\",\"total_spent\"), (\"avg_spent\",\"total_spent\")]\nfor a,b in pairs:\n    if a in df.columns and b in df.columns:\n        x = pd.to_numeric(df[a], errors=\"coerce\"); y = pd.to_numeric(df[b], errors=\"coerce\")\n        ok = x.notna() & y.notna()\n        if ok.sum() > 2:\n            r,p = stats.pearsonr(x[ok], y[ok]); rs,ps = stats.spearmanr(x[ok], y[ok])\n            results_lines += [f\"Pearson {a} vs {b}: r={r:.3f}, p={p:.4g}\", f\"Spearman {a} vs {b}: \u03c1={rs:.3f}, p={ps:.4g}\"]\n\ndef anova_on(target, factor):\n    groups, labels = [], []\n    if target in df.columns and factor in df.columns:\n        for k,g in df[[target,factor]].dropna().groupby(factor):\n            if len(g[target]) > 1: groups.append(g[target].values); labels.append(str(k))\n    if len(groups) >= 2:\n        F, p = stats.f_oneway(*groups); results_lines.append(f\"ANOVA {target} ~ {factor}: F={F:.4f}, p={p:.4g} | groups={labels}\")\n\nfor factor in [\"gender\",\"incomelevel\"]:\n    anova_on(\"total_spent\", factor)\n\nif \"gender\" in df.columns and \"total_spent\" in df.columns:\n    g = df.dropna(subset=[\"gender\",\"total_spent\"]); cats = g[\"gender\"].value_counts().index.tolist()\n    if len(cats) == 2:\n        a = g.loc[g[\"gender\"]==cats[0], \"total_spent\"]; b = g.loc[g[\"gender\"]==cats[1], \"total_spent\"]\n        t, p = stats.ttest_ind(a, b, equal_var=False, nan_policy=\"omit\")\n        results_lines.append(f\"T-test total_spent by gender ({cats[0]} vs {cats[1]}): t={t:.4f}, p={p:.4g}\")\n\ndef chi2_pair(c1, c2):\n    if c1 in df.columns and c2 in df.columns:\n        tab = pd.crosstab(df[c1], df[c2])\n        if tab.shape[0] > 1 and tab.shape[1] > 1:\n            chi2, p, dof, exp = stats.chi2_contingency(tab)\n            results_lines.append(f\"Chi\u00b2 {c1} vs {c2}: chi2={chi2:.3f}, p={p:.4g}\")\nfor c1, c2 in [(\"gender\",\"incomelevel\"), (\"gender\",\"location\")]:\n    chi2_pair(c1, c2)\n\nwith open(OUT_DIR / \"inferential_tests_summary.txt\", \"w\") as f:\n    f.write(\"\\n\".join(results_lines))\nprint(\"\\n\".join(results_lines)); print(\"Saved:\", OUT_DIR / \"inferential_tests_summary.txt\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Part B \u2014 Age Binning + IQR Outliers + Regenerated Plots (Code 2)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Reuse df from Part A\nfor c in [\"age\",\"total_spent\",\"avg_spent\",\"num_transactions\",\"max_transaction\",\"min_transaction\",\"engagement_score\"]:\n    if c in df.columns: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n\n# Age binning\nif \"age\" in df.columns:\n    df.loc[df[\"age\"] < 0, \"age\"] = np.nan\n    age_bins = [0, 18, 25, 35, 50, 65, np.inf]\n    age_labels = [\"\u226418\",\"19\u201325\",\"26\u201335\",\"36\u201350\",\"51\u201365\",\"66+\"]\n    df[\"age_group\"] = pd.cut(df[\"age\"], bins=age_bins, labels=age_labels, right=True, include_lowest=True)\n\n    fig = plt.figure(figsize=(6,4))\n    ax = sns.countplot(x=\"age_group\", data=df, order=age_labels)\n    ax.set_title(\"Customer Count by Age Group\"); ax.set_xlabel(\"Age Group\"); ax.set_ylabel(\"Count\")\n    plt.tight_layout(); fig.savefig(OUT_DIR / \"bar_age_groups.png\"); plt.show()\n\n    if \"total_spent\" in df.columns:\n        fig = plt.figure(figsize=(7,4))\n        sns.barplot(x=\"age_group\", y=\"total_spent\", data=df, estimator=sum, errorbar=None, order=age_labels)\n        plt.title(\"Total Spending by Age Group\"); plt.xlabel(\"Age Group\"); plt.ylabel(\"Total Sales (sum)\")\n        plt.tight_layout(); fig.savefig(OUT_DIR / \"bar_total_spent_by_age_group.png\"); plt.show()\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# IQR outlier flagging\ndef iqr_flags(series):\n    q1 = series.quantile(0.25); q3 = series.quantile(0.75); iqr = q3 - q1\n    lower = q1 - 1.5*iqr; upper = q3 + 1.5*iqr\n    return (series < lower) | (series > upper), lower, upper\n\nnumeric_df = df.select_dtypes(include=[\"number\"]).copy()\noutlier_flags = pd.DataFrame(index=df.index); summary_rows = []\n\nfor col in numeric_df.columns:\n    s = numeric_df[col].dropna()\n    if s.empty:\n        outlier_flags[col+\"_outlier\"] = False\n        summary_rows.append({\"column\": col, \"outliers\": 0, \"lower\": np.nan, \"upper\": np.nan}); continue\n    flags, lb, ub = iqr_flags(numeric_df[col])\n    outlier_flags[col+\"_outlier\"] = flags.fillna(False)\n    summary_rows.append({\"column\": col, \"outliers\": int(flags.sum()), \"lower\": float(lb), \"upper\": float(ub)})\n\noutlier_summary = pd.DataFrame(summary_rows).sort_values(\"outliers\", ascending=False)\ndf_with_flags = pd.concat([df, outlier_flags], axis=1)\noutlier_summary.to_csv(OUT_DIR / \"outlier_summary_iqr.csv\", index=False)\ndf_with_flags.to_csv(OUT_DIR / \"merged_with_outlier_flags.csv\", index=False)\ndisplay(outlier_summary.head(10))\nprint(\"Saved flags ->\", OUT_DIR / \"outlier_summary_iqr.csv\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Optional removal + regenerated plots\nDROP_OUTLIERS = True\n\nif DROP_OUTLIERS:\n    any_outlier = outlier_flags.any(axis=1)\n    df_no_out = df_with_flags.loc[~any_outlier].copy()\n    print(f\"Original rows: {len(df_with_flags):,} | After removing any IQR outlier: {len(df_no_out):,}\")\n    df_no_out.to_csv(\"merged_cleaned_no_outliers.csv\", index=False)\nelse:\n    df_no_out = df_with_flags.copy()\n\ndef save_show(fig, name):\n    p = OUT_DIR / f\"{name}.png\"\n    fig.savefig(p, bbox_inches=\"tight\"); plt.show()\n    print(f\"Saved: {p}\")\n\nfor col in [\"total_spent\",\"avg_spent\",\"max_transaction\",\"min_transaction\",\"age\"]:\n    if col in df.columns:\n        fig = plt.figure(figsize=(6,4)); sns.boxplot(x=df[col])\n        plt.title(f\"Boxplot of {col} (with outliers)\"); save_show(fig, f\"box_{col}_with_outliers\")\n        fig = plt.figure(figsize=(6,4)); sns.boxplot(x=df_no_out[col].dropna())\n        plt.title(f\"Boxplot of {col} (outliers removed)\"); save_show(fig, f\"box_{col}_no_outliers\")\n\nif \"total_spent\" in df.columns:\n    fig = plt.figure(figsize=(6,4)); sns.histplot(df[\"total_spent\"].dropna(), bins=30, kde=True)\n    plt.title(\"Total Spending (with outliers)\"); save_show(fig, \"hist_total_spent_with_outliers\")\n    fig = plt.figure(figsize=(6,4)); sns.histplot(df_no_out[\"total_spent\"].dropna(), bins=30, kde=True)\n    plt.title(\"Total Spending (outliers removed)\"); save_show(fig, \"hist_total_spent_no_outliers\")\n\ndef corr_heatmap(d, title, fname):\n    num = d.select_dtypes(include=[\"number\"])\n    if not num.empty:\n        fig = plt.figure(figsize=(9,6))\n        sns.heatmap(num.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, fmt=\".2f\")\n        plt.title(title); save_show(fig, fname)\n\ncorr_heatmap(df, \"Correlation Heatmap (with outliers)\", \"heatmap_corr_with_outliers\")\ncorr_heatmap(df_no_out, \"Correlation Heatmap (outliers removed)\", \"heatmap_corr_no_outliers\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Inferential checks on cleaned data\nresults = []\n\nif \"age_group\" in df_no_out.columns and \"total_spent\" in df_no_out.columns:\n    groups = [g[\"total_spent\"].dropna().values for _, g in df_no_out[[\"total_spent\",\"age_group\"]].dropna().groupby(\"age_group\")]\n    groups = [g for g in groups if len(g) > 1]\n    if len(groups) >= 2:\n        F, p = stats.f_oneway(*groups); results.append(f\"ANOVA total_spent ~ age_group: F={F:.4f}, p={p:.4g}\")\n\nif \"gender\" in df_no_out.columns and \"total_spent\" in df_no_out.columns:\n    sub = df_no_out.dropna(subset=[\"gender\",\"total_spent\"]); cats = sub[\"gender\"].value_counts().index.tolist()\n    if len(cats) == 2:\n        a = sub.loc[sub[\"gender\"]==cats[0], \"total_spent\"]; b = sub.loc[sub[\"gender\"]==cats[1], \"total_spent\"]\n        t, p = stats.ttest_ind(a, b, equal_var=False, nan_policy=\"omit\")\n        results.append(f\"T-test total_spent by gender ({cats[0]} vs {cats[1]}): t={t:.4f}, p={p:.4g}\")\n\nfor a,b in [(\"num_transactions\",\"total_spent\"), (\"avg_spent\",\"total_spent\"), (\"age\",\"total_spent\")]:\n    if a in df_no_out.columns and b in df_no_out.columns:\n        x = pd.to_numeric(df_no_out[a], errors=\"coerce\"); y = pd.to_numeric(df_no_out[b], errors=\"coerce\")\n        ok = x.notna() & y.notna()\n        if ok.sum() > 2:\n            r,p = stats.pearsonr(x[ok], y[ok]); rs,ps = stats.spearmanr(x[ok], y[ok])\n            results += [f\"Pearson {a} vs {b}: r={r:.3f}, p={p:.4g}\", f\"Spearman {a} vs {b}: \u03c1={rs:.3f}, p={ps:.4g}\"]\n\ndef chi2_pair(d, c1, c2):\n    if c1 in d.columns and c2 in d.columns:\n        tab = pd.crosstab(d[c1], d[c2])\n        if tab.shape[0] > 1 and tab.shape[1] > 1:\n            chi2, p, dof, exp = stats.chi2_contingency(tab)\n            return f\"Chi\u00b2 {c1} vs {c2}: chi2={chi2:.3f}, p={p:.4g}\"\nfor c1, c2 in [(\"gender\",\"incomelevel\"), (\"gender\",\"location\")]:\n    res = chi2_pair(df_no_out, c1, c2)\n    if res: results.append(res)\n\nwith open(OUT_DIR / \"inferential_tests_after_outlier_removal.txt\", \"w\") as f:\n    f.write(\"\\n\".join(results))\nprint(\"\\n\".join(results) if results else \"No inferential results produced (check column availability).\")\nprint(\"Saved:\", OUT_DIR / \"inferential_tests_after_outlier_removal.txt\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "### End of notebook\n\nAll figures/tables are saved into `eda_outputs/`. You can export to PDF via VS Code: `File \u2192 Export As \u2192 PDF`.\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Statistical Notes (Displayed Above Plots)\n\nThis section prints concise statistical results, followed by the corresponding chart.\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# ANOVA \u2014 total_spent by gender (adjust factor/target if needed)\nfactor = \"gender\"\ntarget = \"total_spent\"\n\nif factor in df.columns and target in df.columns:\n    groups = [g[target].dropna().values for _, g in df[[target, factor]].dropna().groupby(factor)]\n    valid = [g for g in groups if len(g) > 1]\n    if len(valid) >= 2:\n        F, p = stats.f_oneway(*valid)\n        print(f\"ANOVA for {target} by {factor}:\")\n        print(f\"F-statistic: {F:.4f}, p-value: {p:.4g}\")\n        print(\"Result:\", \"Significant differences between groups.\" if p < 0.05 else \"No significant differences between groups.\")\n        plt.figure(figsize=(6,4))\n        sns.barplot(data=df, x=factor, y=target, estimator=sum, errorbar=None)\n        plt.title(f\"Total {target.replace('_',' ').title()} by {factor.title()}\")\n        plt.xlabel(factor.title()); plt.ylabel(\"Total Sales (sum)\")\n        plt.tight_layout(); plt.show()\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Correlation heatmap \u2014 with a brief header above plot\nnum_df = df.select_dtypes(include=[\"number\"]).copy()\nif not num_df.empty:\n    print(\"Correlation Heatmap (Numeric Features): values are Pearson r.\")\n    plt.figure(figsize=(9,6))\n    sns.heatmap(num_df.corr(numeric_only=True), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, fmt=\".2f\")\n    plt.title(\"Correlation Heatmap (Numeric Features)\")\n    plt.tight_layout(); plt.show()\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Pairwise Pearson correlation significance report (text only)\ndef pearson_significance_text(dframe):\n    num = dframe.select_dtypes(include=[\"number\"]).dropna(axis=1, how=\"all\")\n    cols = num.columns.tolist()\n    print(\"Pearson Correlation Significance Test:\")\n    for a in cols:\n        for b in cols:\n            if a == b: \n                continue\n            ab = num[[a,b]].dropna()\n            if len(ab) > 2:\n                r, p = stats.pearsonr(ab[a], ab[b])\n                print(f\"{a} vs {b} \u2192 r = {r:+.3f}, p = {p:.4f}\")\n\npearson_significance_text(df)\n# To run on outlier-removed data (if created earlier in the notebook), uncomment:\n# pearson_significance_text(df_no_out)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Scatter example \u2014 print Pearson note then plot\nx, y = \"avg_spent\", \"total_spent\"\nif x in df.columns and y in df.columns:\n    ab = df[[x,y]].dropna()\n    if len(ab) > 2:\n        r, p = stats.pearsonr(ab[x], ab[y])\n        print(f\"Pearson {x} vs {y}: r = {r:+.3f}, p = {p:.4g}\")\n        plt.figure(figsize=(6,4))\n        sns.scatterplot(data=ab, x=x, y=y, alpha=0.6)\n        plt.title(f\"{x.replace('_',' ').title()} vs {y.replace('_',' ').title()}\")\n        plt.tight_layout(); plt.show()\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Time Series \u2014 ADF Stationarity Test and Trend\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# ADF test on monthly total spending (prints results before the plot)\nif all(c in df.columns for c in [\"signupdate\",\"total_spent\"]):\n    # parse dates defensively\n    _tmp = df.copy()\n    _tmp[\"signupdate\"] = pd.to_datetime(_tmp[\"signupdate\"], errors=\"coerce\")\n    ts = (_tmp.dropna(subset=[\"signupdate\",\"total_spent\"])\n              .set_index(\"signupdate\")[\"total_spent\"]\n              .resample(\"MS\").sum())\n\n    if ts.dropna().shape[0] >= 10:  # need enough observations for ADF\n        adf_stat, pval, usedlag, nobs, crit, icbest = adfuller(ts.dropna(), autolag=\"AIC\")\n        print(\"ADF Test for Sales Trend Stationarity:\")\n        print(f\"ADF Statistic: {adf_stat:.4f}, p-value: {pval:.4f}\")\n        print(\"Result:\", \"Reject H0 \u2192 Sales trend is stationary.\" if pval < 0.05 else \"Fail to reject H0 \u2192 Sales trend is non-stationary.\")\n    else:\n        print(\"ADF Test: insufficient monthly observations after resampling.\")\n\n    plt.figure(figsize=(10,4))\n    ts.plot()\n    plt.title(\"Total Spending Over Time (monthly)\")\n    plt.xlabel(\"Month\"); plt.ylabel(\"Sales (sum per month)\")\n    plt.tight_layout(); plt.show()\nelse:\n    print(\"Time series step skipped: columns 'signupdate' and/or 'total_spent' not found.\")\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Chi\u2011Square Tests \u2014 Categorical Associations\n\nAutomatically detects suitable categorical column pairs, prints chi\u2011square statistics, then shows simple bar charts for the top results.\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "from itertools import combinations\n\n# Detect categorical columns (string/object/category) with a reasonable number of levels\ncat_cols = [c for c in df.columns \n            if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\")) \n            and df[c].nunique(dropna=True) >= 2 and df[c].nunique(dropna=True) <= 20]\n\nresults = []\nfor c1, c2 in combinations(cat_cols, 2):\n    tab = pd.crosstab(df[c1], df[c2])\n    # require at least 2x2\n    if tab.shape[0] > 1 and tab.shape[1] > 1:\n        chi2, p, dof, exp = stats.chi2_contingency(tab)\n        results.append((c1, c2, chi2, p, dof, tab.sum().sum()))\n\n# Print summary, sorted by p-value (most significant first)\nif results:\n    results.sort(key=lambda x: x[3])  # by p\n    print(\"Chi\u2011Square summary (top 10 by significance):\")\n    for (c1, c2, chi2, p, dof, n) in results[:10]:\n        print(f\"{c1} vs {c2} \u2192 Chi2: {chi2:.4f}, p-value: {p:.4g}, dof={dof}, N={n}\")\nelse:\n    print(\"No suitable categorical pairs found for chi\u2011square.\")\n"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Plot bar charts for up to the top 3 pairs (most significant p-values)\nmax_plots = 3\nplotted = 0\nfor c1, c2, chi2, p, dof, n in results:\n    if plotted >= max_plots:\n        break\n    print(f\"\\nChi\u2011Square Test for {c1} vs {c2}:\")\n    print(f\"Chi2: {chi2:.4f}, p-value: {p:.4g}\")\n    print(\"Result:\", \"Significant association.\" if p < 0.05 else \"No significant association.\")\n\n    # Simple bar chart: counts by c2\n    plt.figure(figsize=(7,4))\n    pd.crosstab(df[c1], df[c2]).sum(axis=0).plot(kind=\"bar\")\n    plt.ylabel(\"Count\")\n    plt.title(f\"Counts by {c2.title()}\")\n    plt.xlabel(c2.title())\n    plt.tight_layout(); plt.show()\n    plotted += 1\n"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}